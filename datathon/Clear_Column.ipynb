{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Facility Name              Address 1  \\\n",
      "0                Ohana Memorials Mammography Services     1515 W Yakima Ave.   \n",
      "1                          31 Medical Group Aviano AB                  Italy   \n",
      "2                  35th Medical Group Misawa AB Japan              Unit 5024   \n",
      "3     374th MDG Unit 5225 SGCR Yokota AB APO AP 96328         Unit 5225 SGCR   \n",
      "4                                 375th Medical Group        310 W Losey St.   \n",
      "...                                               ...                    ...   \n",
      "8806                         Zwanger-Pesiri Radiology     160 Brentwood Road   \n",
      "8807                         Zwanger-Pesiri Radiology  803-F Montauk Highway   \n",
      "8808                         Zwanger-Pesiri Radiology       1729 N Ocean Ave   \n",
      "8809                   Zwanger-Pesiri Radiology Group       759 Montauk Hwy.   \n",
      "8810                   Zwanger-Pesiri Radiology Group                    LLP   \n",
      "\n",
      "                  Address 2  Address 3        City            State  \\\n",
      "0                       NaN        NaN      Yakima               WA   \n",
      "1          31 Medical Group  Unit 6180         NaN  Air Post Office   \n",
      "2                       NaN        NaN         APO               AP   \n",
      "3       374th Medical Group        NaN         APO               AP   \n",
      "4                       NaN        NaN   Scott AFB               IL   \n",
      "...                     ...        ...         ...              ...   \n",
      "8806                    NaN        NaN   Bay Shore               NY   \n",
      "8807                    NaN        NaN     Shirley               NY   \n",
      "8808                    NaN        NaN     Medford               NY   \n",
      "8809                    NaN        NaN  West Islip               NY   \n",
      "8810  150 East Sunrise Hwy.        NaN         NaN      Lindenhurst   \n",
      "\n",
      "        Zip Code            Phone          Fax     Column_A Column_B Column_C  \\\n",
      "0          98902      509574-3863  509249-5319          NaN      NaN      NaN   \n",
      "1             AE             9604     3.90E+11      3904343      NaN      NaN   \n",
      "2     96319-5300         8.13E+11      8117677          NaN      NaN      NaN   \n",
      "3          96328        425522510    425302026          NaN      NaN      NaN   \n",
      "4     62225-5252      618256-1494  618256-7253          NaN      NaN      NaN   \n",
      "...          ...              ...          ...          ...      ...      ...   \n",
      "8806       11706      631444-5544  631666-9168          NaN      NaN      NaN   \n",
      "8807       11967      631444-5544  631870-8732          NaN      NaN      NaN   \n",
      "8808       11763      631444-5544  631870-8732          NaN      NaN      NaN   \n",
      "8809       11795  516798-42426001  631870-8732          NaN      NaN      NaN   \n",
      "8810          NY            11757  631444-5544  631225-9550      NaN      NaN   \n",
      "\n",
      "     Column_D  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "...       ...  \n",
      "8806      NaN  \n",
      "8807      NaN  \n",
      "8808      NaN  \n",
      "8809      NaN  \n",
      "8810      NaN  \n",
      "\n",
      "[8811 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "df1 = pd.read_csv('beginner.csv')\n",
    "df1copy = df1\n",
    "\n",
    "def sort_column_NaN_last(dataframe, column): # dataframe is three of the important factors [\"City\",\"State\",\"Zip_Code\"]; Column is the target column\n",
    "    output = dataframe.sort_values(by=column, inplace = False, na_position = \"last\")\n",
    "    NaN_count = dataframe[column].value_counts(dropna = False).tolist() # print the nunber of \"NaN\" in one column\n",
    "    #NaN_count = int(NaN_count[1])\n",
    "    return output, NaN_count\n",
    "\n",
    "def sort_column_NaN_first(dataframe, column): # dataframe is three of the important factors [\"City\",\"State\",\"Zip_Code\"];  Column is the target column\n",
    "    output = dataframe.sort_values(by = column, inplace = False, na_position = \"first\")\n",
    "    NaN_count = dataframe[column].value_counts(dropna = False) # print the nunber of \"NaN\" in one column\n",
    "    #print(NaN_count)\n",
    "    return output, NaN_count\n",
    "\n",
    "#clean data in column_d\n",
    "def clear_data_D(dataframe, column):\n",
    "    C_D, C_D_NaN_count = sort_column_NaN_last(dataframe, column)\n",
    "    #print(\"______________\")\n",
    "    #print(C_D, C_D_NaN_count)\n",
    "    C_D = C_D.iloc[:1]\n",
    "    #print(C_D,\"我进来了\")\n",
    "    #row_number = df1copy[df1copy[\"\"]]\n",
    "    wrong_row = C_D.iloc[0] #错误表格\n",
    "    #print(wrong_row,\"这是你要返回的数据\")\n",
    "    print(df1copy)\n",
    "    dataframe = dataframe.dropna(subset=[\"Phone\"]) # 新的dataframe已删除无用行,有用数据\n",
    "    #print(\"dataframe_1 created\")\n",
    "    #print(df1copy)\n",
    "    #print(\"我顶不住了真的顶不住了杀了我吧\")\n",
    "    return wrong_row, dataframe\n",
    "\n",
    "#clean data in column_c\n",
    "def clear_data_C(dataframe, column):\n",
    "    C_C, C_C_NaN_count = sort_column_NaN_last(dataframe, column)\n",
    "    #print(\"______________\")\n",
    "    #print(C_C, C_C_NaN_count)\n",
    "    C_C = C_C.iloc[:13] #replace x with location\n",
    "    #print(C_C,\"我进来了\")\n",
    "    wrong_row = C_C.head(13)\n",
    "    dataframe = dataframe.dropna(subset=[\"Zip Code\"]) # 新的dataframe已删除无用行\n",
    "    #print(\"dataframe edited\")\n",
    "    #print(dataframe.shape)\n",
    "    #print(\"我顶不住了真的顶不住了杀了我吧\")\n",
    "    return wrong_row, dataframe\n",
    "\n",
    "#clean data in column_b\n",
    "def clear_data_B(dataframe, column):\n",
    "    C_B, C_B_NaN_count = sort_column_NaN_last(dataframe, column)\n",
    "    #print(\"______________\")\n",
    "    #print(C_B, C_B_NaN_count)\n",
    "    C_B = C_B.iloc[:161] #replace x with location\n",
    "    #print(C_B,\"我进来了\")\n",
    "    wrong_row = C_B.head(161)\n",
    "    dataframe = dataframe.dropna(subset=[\"State\"]) # 新te的dataframe已删除无用行\n",
    "    #print(\"dataframe edited\")\n",
    "    #print(dataframe.shape)\n",
    "    #print(\"我顶不住了真的顶不住了杀了我吧\")\n",
    "    return wrong_row, dataframe\n",
    "\n",
    "#clean data in column_a\n",
    "def clear_data_A(dataframe, column):\n",
    "    C_A, C_A_NaN_count = sort_column_NaN_last(dataframe, column)\n",
    "    #print(\"______________\")\n",
    "    #print(C_A, C_A_NaN_count)\n",
    "    CAC = C_A.iloc[:1712] #replace x with location\n",
    "   # print(C_A,\"我进来了\")\n",
    "    wrong_row = C_A.head(1712)\n",
    "    dataframe = dataframe.dropna(subset=[\"City\"]) # 新的dataframe已删除无用行\n",
    "    return wrong_row, dataframe\n",
    "\n",
    "#rename the column\n",
    "def rename_column_D(wrong_row):\n",
    "    #target_rename_Row, useful_data = clear_data_D(df1copy, \"Column_D\")# 给定需要重命名的目标行，这里是Column_D\n",
    "    target_rename_Row = wrong_row.rename({\"Column_A\":\"State\",\"State\": \"Column_A\"}) # 替换title {'a': 'X', 'b': 'Y'}, axis=1\n",
    "    target_rename_Row = target_rename_Row[[\"State\"]]\n",
    "    #print(target_rename_Row,\"更新数据集！！！\")\n",
    "    return target_rename_Row\n",
    "\n",
    "def rename_column_C(wrong_row):\n",
    "    #target_rename_Row, useful_data = clear_data_D(df1copy, \"Column_C\")# 给定需要重命名的目标行，这里是Column_D\n",
    "    target_rename_Row = wrong_row.rename(columns={\"Fax\":\"State\",\"State\": \"Fax\"}) # 替换title\n",
    "    target_rename_Row = target_rename_Row[[\"State\"]]\n",
    "    #print(target_rename_Row,\"更新数据集！！！\")\n",
    "    return target_rename_Row\n",
    "\n",
    "def rename_column_B(wrong_row):\n",
    "    #target_rename_Row, useful_data= clear_data_D(df1copy, \"Column_B\")# 给定需要重命名的目标行，这里是Column_D\n",
    "    target_rename_Row = wrong_row.rename(columns={\"Phone\":\"State\",\"State\": \"Phone\"}) # 替换title\n",
    "    target_rename_Row = target_rename_Row[[\"State\"]]\n",
    "    #print(target_rename_Row,\"更新数据集！！！\")\n",
    "    return target_rename_Row\n",
    "\n",
    "def rename_column_A(wrong_row):\n",
    "    #target_rename_Row, useful_data = clear_data_D(df1copy, \"Column_A\")# 给定需要重命名的目标行，这里是Column_D\n",
    "    target_rename_Row = wrong_row.rename(columns={\"Zip Code\":\"State\",\"State\": \"Zip Code\"}) # 替换title\n",
    "    target_rename_Row = target_rename_Row[[\"State\"]]\n",
    "    #print(target_rename_Row,\"更新数据集！！！\")\n",
    "    return target_rename_Row\n",
    "\n",
    "\n",
    "data_D, data_after_D = clear_data_D(df1copy, 'Column_D')\n",
    "data_DD = rename_column_D(data_D)\n",
    "\n",
    "data_C, data_after_C = clear_data_C(data_after_D, 'Column_C')\n",
    "data_CC = rename_column_C(data_C)\n",
    "\n",
    "data_B, data_after_B = clear_data_B(data_after_C, 'Column_B')\n",
    "data_BB = rename_column_B(data_B)\n",
    "\n",
    "data_A, data_after_A = clear_data_A(data_after_B, 'Column_A')\n",
    "data_AA = rename_column_A(data_A)\n",
    "\n",
    "with open('variables.pkl', 'wb') as f:\n",
    "    pickle.dump((data_AA, data_BB, data_CC, data_DD, data_after_A), f)\n",
    "\n",
    "#print(sort_column_NaN_first(data_after_B, 'Column_A'))\n",
    "#rename_column_C()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c683adaff7d39edece3d9b29c0f015e5ed01db8984d2a591b7486043b1a59aa5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
